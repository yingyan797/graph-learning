{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Investigating Topology in Node-Based Classification Using GNNs\n",
    "\n",
    "In this section, we will explore the impact of graph topology on node-based classification using GNNs. The experiments will focus on analyzing different topological measures, visualizing their distributions, and evaluating GCN performance on 2 graphs with different topologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from graph_ricci_curvature import GraphRicciCurvature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function and code for loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1_TRAIN_FILE_NAME = \"q3_G1_train.json\"\n",
    "G1_EVAL_FILE_NAME = \"q3_G1_eval.json\"\n",
    "\n",
    "G1_TRAIN_DATA_PATH = os.path.join(\"data\",G1_TRAIN_FILE_NAME)\n",
    "G1_EVAL_DATA_PATH = os.path.join(\"data\",G1_EVAL_FILE_NAME)\n",
    "\n",
    "G2_TRAIN_FILE_NAME = \"q3_G2_train.json\"\n",
    "G2_EVAL_FILE_NAME = \"q3_G2_eval.json\"\n",
    "\n",
    "G2_TRAIN_DATA_PATH = os.path.join(\"data\",G2_TRAIN_FILE_NAME)\n",
    "G2_EVAL_DATA_PATH = os.path.join(\"data\",G2_EVAL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to load the data\n",
    "def create_Adj_matrix(N, edge_index):\n",
    "    \"\"\"Creates the adjacency matrix\"\"\"\n",
    "    A = torch.zeros((N, N), dtype=torch.float)\n",
    "    for idx, jdx in edge_index:\n",
    "        A[idx, jdx] = 1\n",
    "        A[jdx, idx] = 1\n",
    "    return A\n",
    "\n",
    "def read_json_data(file_path, has_label=True):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    if not type(data) == list:\n",
    "        item = data\n",
    "        X = torch.tensor(item['features'], dtype=torch.float)\n",
    "        N = len(X)\n",
    "        A = create_Adj_matrix(N, item['edge_index'])\n",
    "        if has_label:\n",
    "            y = torch.tensor(item['label'], dtype=torch.long)\n",
    "        else:\n",
    "            y = None\n",
    "        return (X,A,y)\n",
    "\n",
    "    graph_data = []\n",
    "    for item in data:\n",
    "        X = torch.tensor(item['features'], dtype=torch.float)\n",
    "        N = len(X)\n",
    "        A = create_Adj_matrix(N, item['edge_index'])\n",
    "        if has_label:\n",
    "            y = torch.tensor(item['label'], dtype=torch.long)\n",
    "        else:\n",
    "            y = None\n",
    "        \n",
    "        graph_data.append((X,A,y))\n",
    "    \n",
    "    return graph_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.1 - Analyzing the Graphs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.1.b Visualizing and Comparing Topological and Geometric Measures of Two Graphs\n",
    "\n",
    "Implement the following three functions to visualize and compare structural properties of two given graphs:\n",
    "\n",
    "- `plot_node_degree_distribution_two_graphs`\n",
    "- `plot_betweenness_centrality_distribution_two_graphs`\n",
    "- `plot_ollivier_ricci_curvature_distribution_two_graphs`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_node_degree(A):\n",
    "    \"\"\"\n",
    "    Given an adjacency matrix A of shape (N, N),\n",
    "    return the degree (row sum) for each of the N nodes.\n",
    "    \"\"\"\n",
    "    degrees = A.sum(dim=1)  # sum across columns\n",
    "    return degrees\n",
    "\n",
    "# ####################################################\n",
    "# MODIFY THE CODE BELOW \n",
    "# ####################################################  \n",
    "\n",
    "\n",
    "def plot_node_degree_distribution_two_graphs(A1, A2, ...):\n",
    "    \"\"\"\n",
    "    Plots the node degree distributions of two graphs\n",
    "    with adjacency matrices A1 and A2 (each of shape (N, N))\n",
    "    in a single figure.\n",
    "    \n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####################################################\n",
    "# MODIFY THE CODE BELOW \n",
    "# ####################################################  \n",
    "\n",
    "def plot_betweenness_distribution_two_graphs(A1, A2, ...):\n",
    "    \"\"\"\n",
    "    Plots the betweenness centrality distributions of two graphs\n",
    "    defined by adjacency matrices A1 and A2 (each of shape (N, N)) \n",
    "    in a single figure.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####################################################\n",
    "# MODIFY THE CODE BELOW \n",
    "# ####################################################  \n",
    "\n",
    "def plot_ricci_curvature_distribution_two_graphs(A1, A2, ...):\n",
    "    \"\"\"\n",
    "    Plots the Ollivier-Ricci curvature distributions for two graphs\n",
    "    defined by adjacency matrices A1 and A2 (PyTorch tensors).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    A1, A2 : torch.Tensor\n",
    "        Adjacency matrices for two undirected graphs (NxN).\n",
    "    \"\"\"\n",
    "    # 1) Convert PyTorch adjacency -> NumPy -> NetworkX Graph\n",
    "    A1_np = A1.numpy()\n",
    "    A2_np = A2.numpy()\n",
    "\n",
    "    G1 = nx.from_numpy_array(A1_np)\n",
    "    G2 = nx.from_numpy_array(A2_np)\n",
    "\n",
    "    # 2) Instantiate OllivierRicci object for each graph\n",
    "    ricci_calculator_G1 = GraphRicciCurvature(G1)\n",
    "    ricci_calculator_G2 = GraphRicciCurvature(G2)\n",
    "\n",
    "    # 3) Compute the Ricci curvature\n",
    "    curvatures1 = ricci_calculator_G1.compute_ricci_curvatures()\n",
    "    curvatures2 = ricci_calculator_G2.compute_ricci_curvatures()\n",
    "\n",
    "    # After computation, the Ricci curvature for each edge is stored in G[u][v][\"ricciCurvature\"]\n",
    "\n",
    "    # 4) Gather edge-level Ricci curvature values\n",
    "    ricci_values_G1 = []\n",
    "    for (u, v), val in curvatures1.items():\n",
    "        ricci_values_G1.append(val)\n",
    "\n",
    "    ricci_values_G2 = []\n",
    "    for (u, v), val in curvatures2.items():\n",
    "        ricci_values_G2.append(val)\n",
    "\n",
    "    # Continue with plotting ...\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1_train = read_json_data(G1_TRAIN_DATA_PATH, has_label=True) #returns a list of (X,A,y) - features, Adj Matrix, per Graph label\n",
    "G2_train = read_json_data(G2_TRAIN_DATA_PATH, has_label=True) #returns a list of (X,A,y) - features, Adj Matrix, per Graph label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_node_degree_distribution_two_graphs(G1_train[1], G2_train[1], ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_betweenness_distribution_two_graphs(G1_train[1], G2_train[1], ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ricci_curvature_distribution_two_graphs(G1_train[1], G2_train[1], ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.1.c Visualizing the Graphs\n",
    "\n",
    "Implement the `plot_graph` function to generate visual representations of both graphs. Ensure that the plots are clear and well-formatted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(A, ...):\n",
    "    \"\"\"\n",
    "    Plots a graph defined by adjacency matrix A.\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : torch.Tensor\n",
    "        Adjacency matrix of shape (N, N).\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(G1_train[1], ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(G2_train[1], ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.1.d Visualizing Node Feature Distributions\n",
    "\n",
    "- Implement the function `plot_node_feature_dist_by_class_two_graphs` to visualize the average node feature distribution per class for two given graphs.\n",
    "\n",
    "- Do not consider the distribution of a specific feature $ x_i $, consider the mean of the feature vector $ \\mathbf{x} $ for each node.\n",
    "\n",
    "- The function should generate a plot similar to Figure 3 in the Coursework Desciription PDF.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_node_feature_dist_by_class_two_graphs(...):\n",
    "    \"\"\"\n",
    "    Plots the distribution of the average node features by class for two graphs.\n",
    "\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_node_feature_dist_by_class_two_graphs(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.2 -  Evaluating GCN Performance on Different Graph Structures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions for normalising the A matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to normalise the A matrix\n",
    "def symmetric_normalize(A_tilde):\n",
    "    \"\"\"\n",
    "    Performs symmetric normalization of A_tilde (Adj. matrix with self loops):\n",
    "      A_norm = D^{-1/2} * A_tilde * D^{-1/2}\n",
    "    Where D_{ii} = sum of row i in A_tilde.\n",
    "\n",
    "    A_tilde (N, N): Adj. matrix with self loops\n",
    "    Returns:\n",
    "      A_norm : (N, N)\n",
    "    \"\"\"\n",
    "\n",
    "    eps = 1e-5\n",
    "    d = A_tilde.sum(dim=1) + eps\n",
    "    D_inv = torch.diag(torch.pow(d, -0.5))\n",
    "    return D_inv @ A_tilde @ D_inv\n",
    "\n",
    "\n",
    "def patch_A_matrix(A):\n",
    "    \"\"\"Patches the A matrix\"\"\"\n",
    "    A = A + torch.eye(A.size(0))\n",
    "    A = symmetric_normalize(A)\n",
    "    return A\n",
    "\n",
    "def patch_A_for_dataset(dataset):\n",
    "    \"\"\"Patches the A matrix for a dataset (list)\"\"\"\n",
    "    dataset = [ (X, patch_A_matrix(A), y) for X,A,y in dataset]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function for plotting training runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for plotting:\n",
    "\n",
    "def plot_training_and_validation(training_losses, validation_losses, aggregation=\"mean\", graph1_label=\"Training Accuracy\", graph2_label=\"Validation Accuracy\", x_label=\"Epoch\",title=None):\n",
    "    \"\"\"\n",
    "    Plots the validation accuracy and training loss over epochs.\n",
    "    Args:\n",
    "        validation_losses: List of validation accuracies (or losses)\n",
    "        training_losses: List of training accuracies (or losses)\n",
    "        aggregation: Aggregation method used (default: \"mean\")\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Create figure with two y-axes\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "    ax2 = ax1.twinx()\n",
    "    \n",
    "    # Plot training loss on the first y-axis\n",
    "    epochs = range(1, len(training_losses) + 1)\n",
    "    line1 = ax1.plot(epochs, training_losses, 'r-', label=f'{graph1_label}')\n",
    "    ax1.set_xlabel(f\"x_label\")\n",
    "    ax1.set_ylabel(f'{graph1_label}', color='r')\n",
    "    ax1.tick_params(axis='y', labelcolor='r')\n",
    "    \n",
    "    # Plot validation accuracy on the second y-axis\n",
    "    line2 = ax2.plot(epochs, validation_losses, 'b-', label=f'{graph2_label}')\n",
    "    ax2.set_ylabel(f'{graph2_label}', color='b')\n",
    "    ax2.tick_params(axis='y', labelcolor='b')\n",
    "    \n",
    "    # Add title and grid\n",
    "    if not title:\n",
    "        title = f'Training Accuracy and Validation Accuracy Over Time\\nAggregation: {aggregation}'\n",
    "    plt.title(title)\n",
    "\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Add legend\n",
    "    lines = line1 + line2\n",
    "    labels = [l.get_label() for l in lines]\n",
    "    ax1.legend(lines, labels, loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provided GCN Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Provided GCN Implementation\n",
    "class GCNLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    A single layer of a Graph Convolutional Network (GCN).\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, output_dim, use_nonlinearity=True):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.use_nonlinearity = use_nonlinearity\n",
    "        self.Omega = nn.Parameter(torch.randn(input_dim, output_dim) * torch.sqrt(torch.tensor(2.0) / (input_dim + output_dim)))\n",
    "        self.beta = nn.Parameter(torch.zeros(output_dim))\n",
    "\n",
    "    def forward(self, H_k, A_normalized):\n",
    "        agg = torch.matmul(A_normalized, H_k) # local agg\n",
    "        H_k_next = torch.matmul(agg, self.Omega) + self.beta\n",
    "        return F.relu(H_k_next) if self.use_nonlinearity else H_k_next\n",
    "\n",
    "class GraphNeuralNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple Graph Neural Network model using two layers of Graph Convolutional Network (GCN)\n",
    "    for binary classification. The sigmoid activation is applied in the output layer only if\n",
    "    use_nonlinearity is set to True.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(GraphNeuralNetwork, self).__init__()\n",
    "\n",
    "        # Define GCN layers\n",
    "        self.gcn1 = GCNLayer(input_dim, hidden_dim, True)\n",
    "        self.gcn2 = GCNLayer(hidden_dim, 1, False)\n",
    "\n",
    "    def forward(self, A, X, **kwargs):\n",
    "        # Pass through GCN layers\n",
    "        H1 = self.gcn1(X, A)\n",
    "        H2 = self.gcn2(H1, A)  # Output shape: (num_nodes, 1)\n",
    "\n",
    "        output = torch.sigmoid(H2)  # Sigmoid activation per node\n",
    "        if torch.isnan(output).any():\n",
    "            output = torch.where(torch.isnan(output), torch.zeros_like(output), output)\n",
    "\n",
    "        if kwargs.get(\"return_embeddings\", None):\n",
    "            return output, (H1, H2)\n",
    "        else:\n",
    "            return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions for training GCN on a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import binary_cross_entropy\n",
    "from sklearn.metrics import accuracy_score, classification_report,precision_recall_fscore_support\n",
    "\n",
    "def train_model(\n",
    "    model,\n",
    "    G_train,\n",
    "    G_val,\n",
    "    num_epochs=10,\n",
    "    lr=0.0001,\n",
    "    verbose=True,\n",
    "    **kwargs,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train the model, validate every 'validate_every' epochs, and pick the \n",
    "    checkpoint with best validation accuracy.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : torch.nn.Module\n",
    "        The PyTorch model to train.\n",
    "    G_train  = (X_train,A_train,y_train) : input\n",
    "        the Graph 1\n",
    "    Y_train = (X_val,A_val,y_val)\n",
    "        the Graph 2\n",
    "    num_epochs : int\n",
    "        Number of training epochs.\n",
    "    lr : float\n",
    "        Learning rate for the optimizer.\n",
    "    verbose: bool\n",
    "        whether to display the loss, f1 and val_f1\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    loss_history : list\n",
    "        The training loss history across epochs.\n",
    "    f1_train_history : list\n",
    "        train F1s during training\n",
    "    f1_val_history : list\n",
    "        val F1s during training\n",
    "    \"\"\"\n",
    "    X_train, A_train, y_train = G_train\n",
    "    X_val, A_val, y_val = G_val\n",
    "\n",
    "    model.train()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "    loss_history = []\n",
    "    train_f1_history = []\n",
    "    validation_f1_history = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # A single Epoch training.\n",
    "        # TRAINING\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        if kwargs.get(\"return_embeddings\", None):\n",
    "            out, embeddings= model(A_train, X_train, **kwargs)\n",
    "        else:\n",
    "            out = model(A_train, X_train, **kwargs)\n",
    "        out = out.squeeze(-1)  # shape: (N,) if needed\n",
    "        y_float = y_train.float()  # for BCE\n",
    "\n",
    "        # Compute training loss\n",
    "        loss = binary_cross_entropy(out, y_float)\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Record training loss\n",
    "        loss_value = loss.item()\n",
    "        \n",
    "        # EVALUATION\n",
    "        loss_history.append(loss_value)\n",
    "        train_prec, train_rec, train_f1, _ = evaluate_model(model, X_train, A_train, y_train)\n",
    "        val_prec, val_rec, val_f1, _ = evaluate_model(model,  X_val, A_val, y_val)\n",
    "\n",
    "        train_f1_history.append(train_f1)\n",
    "        validation_f1_history.append(val_f1)                     \n",
    "        # Evaluating the model\n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch+1}, Training Loss: {loss_value}, Train F1: {train_f1:.4f}, Validation F1: {val_f1:.4f}\")\n",
    "            \n",
    "    if kwargs.get(\"return_embeddings\", None):\n",
    "        return loss_history, train_f1_history, validation_f1_history, embeddings\n",
    "    else:\n",
    "        return loss_history, train_f1_history, validation_f1_history\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model(model, X,A,y, **kwargs):\n",
    "    \"\"\"\n",
    "    Runs forward pass, calculates binary predictions (threshold=0.5),\n",
    "    and returns the accuracy score.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    if kwargs.get(\"return_embeddings\", None):\n",
    "        out,_ = model(A,X,**kwargs)  # shape: (N, 1)\n",
    "    else:\n",
    "        out = model(A,X,**kwargs)  # shape: (N, 1)\n",
    "    out = out.squeeze(-1)  # shape: (N,)\n",
    "    preds = (out >= 0.5).long()\n",
    "\n",
    "    y_true = y.cpu().numpy()\n",
    "    y_pred = preds.cpu().numpy()\n",
    "\n",
    "    return precision_recall_fscore_support(y_true, y_pred, average=\"micro\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.2.a - Implementation of Layered GCN\n",
    "\n",
    "\n",
    "• Implement a GCN where layers can be passed as input parameter and that can return all\n",
    "embedding layers. (If you will not be able to do so, to get results implement one class per\n",
    "layer).\n",
    "\n",
    "• Train the GCN on G1 and G2 independently. Plot your results. (Note: you don’t need to\n",
    "get a high performance at this stage, just make sure it trains)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION Q3.2.a\n",
    "# ####################################################\n",
    "# MODIFY THE CODE BELOW \n",
    "# ####################################################  \n",
    "\n",
    "\n",
    "\n",
    "# ####################################################\n",
    "# END OF MODIFICATION\n",
    "# ####################################################  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to run the training and evaluation of the model with different number of layers.\n",
    "\n",
    "Adapt it as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data\n",
    "G1_train = read_json_data(G1_TRAIN_DATA_PATH, has_label=True) #returns a list of (X,A,y) - features, Adj Matrix, per Graph label\n",
    "G1_eval = read_json_data(G1_EVAL_DATA_PATH, has_label=True) #returns a list of (X,A,y) - features, Adj Matrix, per Graph label\n",
    "\n",
    "G2_train = read_json_data(G2_TRAIN_DATA_PATH, has_label=True) #returns a list of (X,A,y) - features, Adj Matrix, per Graph label\n",
    "G2_eval = read_json_data(G2_EVAL_DATA_PATH, has_label=True) #returns a list of (X,A,y) - features, Adj Matrix, per Graph label\n",
    "\n",
    "# Initialising the model\n",
    "input_dim = 10\n",
    "hidden_dim = 8\n",
    "num_layers = 4\n",
    "model = GraphNeuralNetwork(input_dim, hidden_dim, num_layers=num_layers)\n",
    "print(model)\n",
    "\n",
    "losses, train_f1, val_f1 = train_model(\n",
    "    model,\n",
    "    G1_train,\n",
    "    G1_eval,\n",
    "    num_epochs=200,\n",
    "    lr=0.0005,\n",
    "    verbose=True,\n",
    ")\n",
    "plot_training_and_validation(losses, val_f1)\n",
    "\n",
    "\n",
    "model = GraphNeuralNetwork(input_dim, hidden_dim, num_layers=num_layers)\n",
    "print(model)\n",
    "\n",
    "losses, train_f1, val_f1 = train_model(\n",
    "    model,\n",
    "    G1_train,\n",
    "    G1_eval,\n",
    "    num_epochs=200,\n",
    "    lr=0.0005,\n",
    "    verbose=True,\n",
    ")\n",
    "plot_training_and_validation(losses, val_f1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.2.b - Plotting of t-SNE Embeddings for Graph Neural Networks\n",
    "\n",
    "• Use t-SNE to visualize the node embeddings for the final layer of the GCN for each graph\n",
    "for both training and evaluation data, use the labels as class labels for the tsne plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION Q3.5.b\n",
    "# ####################################################\n",
    "# MODIFY THE CODE BELOW \n",
    "# ####################################################  \n",
    "\n",
    "def plot_tsne(embeddings, labels=None, layer_to_plot=-1):\n",
    "    \"\"\"\n",
    "    embeddings (list):\n",
    "        list of embeddings (layer 2, ..., layer N)\n",
    "        NOTE: for num_layer = 1 there is no embedding (as it is just the input)\n",
    "    \n",
    "    labels (list):\n",
    "        list of labels\n",
    "    \n",
    "    layer_to_plot (int):\n",
    "        which layer to plot (default -1, i.e. the last layer)\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# ####################################################\n",
    "# END OF MODIFICATION\n",
    "# ####################################################  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the t-SNE embeddings\n",
    "\n",
    "Adapt as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "G1_train = read_json_data(G1_TRAIN_DATA_PATH, has_label=True) #returns a list of (X,A,y) - features, Adj Matrix, per Graph label\n",
    "G1_eval = read_json_data(G1_EVAL_DATA_PATH, has_label=True) #returns a list of (X,A,y) - features, Adj Matrix, per Graph label\n",
    "\n",
    "G2_train = read_json_data(G2_TRAIN_DATA_PATH, has_label=True) #returns a list of (X,A,y) - features, Adj Matrix, per Graph label\n",
    "G2_eval = read_json_data(G2_EVAL_DATA_PATH, has_label=True) #returns a list of (X,A,y) - features, Adj Matrix, per Graph label\n",
    "\n",
    "# Initialising the model\n",
    "input_dim = 10\n",
    "hidden_dim = 8\n",
    "num_layers = 4\n",
    "model = GraphNeuralNetwork(input_dim, hidden_dim, num_layers=num_layers)\n",
    "print(model)\n",
    "\n",
    "losses, train_f1, val_f1, last_embeddings = train_model(\n",
    "    model,\n",
    "    G1_train,\n",
    "    G1_eval,\n",
    "    num_epochs=200,\n",
    "    lr=0.0005,\n",
    "    verbose=True,\n",
    "    return_embeddings = True #NOTE we added this parameter\n",
    ")\n",
    "plot_training_and_validation(losses, val_f1)\n",
    "\n",
    "X,A,y = G1_train\n",
    "print(len(last_embeddings))\n",
    "plot_tsne(last_embeddings, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.2.c - Training the Model on Merged Graphs G = G1 ∪ G\n",
    "\n",
    "• Implement a GCN that trains on both graphs at once. Plot the training curve.\n",
    "\n",
    "• Compare the performance of G = G1 ∪ G2 against training on G1 and G2, respectively.\n",
    "\n",
    "• Plot TSNE plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION Q3.2.c\n",
    "# ####################################################\n",
    "# MODIFY THE CODE BELOW \n",
    "# ####################################################  \n",
    "\n",
    "# Implement the training of G = {G1 U G2}\n",
    "\n",
    "# In the end return a single function:\n",
    "def train_G1UG2(G1_train, G1_eval, G2_train, G2_eval, num_epochs=200, lr=0.001, verbose=True):\n",
    "    \"\"\"\"\"\"\n",
    "    # INSERT necessary things\n",
    "    return losses, train_f1, val_f1\n",
    "\n",
    "# ####################################################\n",
    "# END OF MODIFICATION\n",
    "# ####################################################  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data\n",
    "G1_train = read_json_data(G1_TRAIN_DATA_PATH, has_label=True) #returns a list of (X,A,y) - features, Adj Matrix, per Graph label\n",
    "G1_eval = read_json_data(G1_EVAL_DATA_PATH, has_label=True) #returns a list of (X,A,y) - features, Adj Matrix, per Graph label\n",
    "\n",
    "G2_train = read_json_data(G2_TRAIN_DATA_PATH, has_label=True) #returns a list of (X,A,y) - features, Adj Matrix, per Graph label\n",
    "G2_eval = read_json_data(G2_EVAL_DATA_PATH, has_label=True) #returns a list of (X,A,y) - features, Adj Matrix, per Graph label\n",
    "\n",
    "losses, train_f1, val_f1 = train_G1UG2(G1_train, G1_eval, G2_train, G2_eval, num_epochs=200, lr=0.001, verbose=True)\n",
    "\n",
    "plot_training_and_validation(losses, val_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.2.d Implement & discuss what you observe.\n",
    "\n",
    "• Compare training results, embeddings, and overall observations between independent and\n",
    "merged training.\n",
    "\n",
    "• Formulate a hypothesis explaining your observations.\n",
    "\n",
    "• Discuss different implementation options for training on both graphs, including your choice.\n",
    "(e.g. what model modifications are possible; what training modifications are possible?)\n",
    "\n",
    "• Provide relevant plots and tables where appropriate.\n",
    "\n",
    "• Bonus: Implement a modification (or alternative approach) for training on G1 ∪ G2 and\n",
    "compare outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION Q3.2.d\n",
    "# ####################################################\n",
    "# MODIFY THE CODE BELOW \n",
    "# ####################################################  \n",
    "\n",
    "# Implement the training of G = {G1 U G2}\n",
    "\n",
    "# In the end return a single function:\n",
    "def train_G1UG2_v2(G1_train, G1_eval, G2_train, G2_eval, num_epochs=200, lr=0.001, verbose=True):\n",
    "    \"\"\"\"\"\"\n",
    "    # INSERT necessary things\n",
    "    return losses, train_f1, val_f1\n",
    "\n",
    "# ####################################################\n",
    "# END OF MODIFICATION\n",
    "# ####################################################  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runnning the evaluation. \n",
    "\n",
    "Note: It is optional to run this particular evaluation. You can modify it as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data\n",
    "G1_train = read_json_data(G1_TRAIN_DATA_PATH, has_label=True) #returns a list of (X,A,y) - features, Adj Matrix, per Graph label\n",
    "G1_eval = read_json_data(G1_EVAL_DATA_PATH, has_label=True) #returns a list of (X,A,y) - features, Adj Matrix, per Graph label\n",
    "\n",
    "G2_train = read_json_data(G2_TRAIN_DATA_PATH, has_label=True) #returns a list of (X,A,y) - features, Adj Matrix, per Graph label\n",
    "G2_eval = read_json_data(G2_EVAL_DATA_PATH, has_label=True) #returns a list of (X,A,y) - features, Adj Matrix, per Graph label\n",
    "\n",
    "losses, train_f1, val_f1 = train_G1UG2_v2(G1_train, G1_eval, G2_train, G2_eval, num_epochs=200, lr=0.001, verbose=True)\n",
    "\n",
    "plot_training_and_validation(losses, val_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Topological changes to improve training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.3.a - Plot the Ricci Curvature for each edge.\n",
    "\n",
    "• Plot a barplot of the the Ricci curvature per edge, where the x-axis are the edges and y-axis\n",
    "is the ricci curvature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION Q3.3.a\n",
    "# ####################################################\n",
    "# MODIFY THE CODE BELOW \n",
    "# ####################################################  \n",
    "\n",
    "\n",
    "# Load data\n",
    "G1_train = read_json_data(G1_TRAIN_DATA_PATH, has_label=True) #returns a list of (X,A,y) - features, Adj Matrix, per Graph label\n",
    "G1_eval = read_json_data(G1_EVAL_DATA_PATH, has_label=True) #returns a list of (X,A,y) - features, Adj Matrix, per Graph label\n",
    "\n",
    "G2_train = read_json_data(G2_TRAIN_DATA_PATH, has_label=True) #returns a list of (X,A,y) - features, Adj Matrix, per Graph label\n",
    "G2_eval = read_json_data(G2_EVAL_DATA_PATH, has_label=True) #returns a list of (X,A,y) - features, Adj Matrix, per Graph label\n",
    "\n",
    "\n",
    "# Plot curvature against edges\n",
    "from graph_ricci_curvature import GraphRicciCurvature \n",
    "\n",
    "# plot_ricci_per_edge()\n",
    "\n",
    "\n",
    "# ####################################################\n",
    "# END OF MODIFICATION\n",
    "# ####################################################   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.3.b Investigate the extreme case topologies.\n",
    "\n",
    "• How would you modify a topology so that the graph structure is ignored, making the GNN\n",
    "behave like an MLP?\n",
    "\n",
    "• What would an ideal graph structure be for optimal training and testing if labels were\n",
    "available (both during training and testing)?\n",
    "\n",
    "• What are you observations? Analyze the scores and what does it mean about the dataset?\n",
    "\n",
    "• Provide relevant plots and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION Q3.3.b\n",
    "# ####################################################\n",
    "# MODIFY THE CODE BELOW \n",
    "# ####################################################  \n",
    "\n",
    "def augment_graph_gold_labels(G):\n",
    "    \"\"\"Augment graph to return A that would be 'perfect'\"\"\"\n",
    "    X,A,y = G\n",
    "    return X,A,y\n",
    "\n",
    "def augment_graph_no_effect(G):\n",
    "    \"\"\"Modify graph to return A that has no 'effect'\"\"\"\n",
    "    X,A,y = G\n",
    "    return X,A,y\n",
    "\n",
    "    \n",
    "def improved_training(\n",
    "        G_train,\n",
    "        G_eval,\n",
    "        model_params,\n",
    "        num_epochs=200,\n",
    "        lr=0.0005,\n",
    "        verbose=True,\n",
    "        return_embeddings = True,\n",
    "        change_topology_params = {},\n",
    "    ):\n",
    "    \"\"\"\n",
    "    How can you improve the topologies to train better.\n",
    "    \"\"\"\n",
    "    if change_topology_params[\"augmentation_strategy\"] == \"no_effect\":\n",
    "        augmentation_function = augment_graph_no_effect\n",
    "    elif change_topology_params[\"augmentation_strategy\"] == \"gold\":\n",
    "        augmentation_function = augment_graph_gold_labels\n",
    "    else:\n",
    "        raise NotImplementedError(\"This augmentation setting is not implemented.\")\n",
    "\n",
    "    G_train = augmentation_function(G_train)\n",
    "    G_train = G_train[0],symmetric_normalize(G_train[1]),G_train[2]\n",
    "\n",
    "    G_eval = augmentation_function(G_eval)\n",
    "    G_eval = G_eval[0],symmetric_normalize(G_eval[1]),G_eval[2]\n",
    "\n",
    "    # Initialising the model\n",
    "    model = GraphNeuralNetwork(**model_params)\n",
    "    print(model)\n",
    "\n",
    "    losses, train_f1, val_f1, last_embeddings = train_model(\n",
    "        model,\n",
    "        G_train,\n",
    "        G_eval,\n",
    "        num_epochs=num_epochs,\n",
    "        lr=lr,\n",
    "        verbose=verbose,\n",
    "        return_embeddings = True\n",
    "    )\n",
    "    return losses, train_f1, val_f1, last_embeddings\n",
    "\n",
    "# ####################################################\n",
    "# END OF MODIFICATION\n",
    "# ####################################################  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to run improvement\n",
    "Note: run it a few times to see what performance can be reached on the eval dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "G1_train = read_json_data(G1_TRAIN_DATA_PATH, has_label=True) #returns a list of (X,A,y) - features, Adj Matrix, per Graph label\n",
    "G1_eval = read_json_data(G1_EVAL_DATA_PATH, has_label=True) #returns a list of (X,A,y) - features, Adj Matrix, per Graph label\n",
    "\n",
    "G2_train = read_json_data(G2_TRAIN_DATA_PATH, has_label=True) #returns a list of (X,A,y) - features, Adj Matrix, per Graph label\n",
    "G2_eval = read_json_data(G2_EVAL_DATA_PATH, has_label=True) #returns a list of (X,A,y) - features, Adj Matrix, per Graph label\n",
    "\n",
    "model_params = {    \n",
    "    \"input_dim\":10, \n",
    "    \"hidden_dim\":8,\n",
    "    \"num_layers\":4,\n",
    "}\n",
    "\n",
    "change_topology_params = {\n",
    "    \"augmentation_strategy\":\"no_effect\",\n",
    "    \"normalise\" : False,\n",
    "}\n",
    "\n",
    "# change_topology_params = {\n",
    "#     \"augmentation_strategy\":\"gold\",\n",
    "#     \"normalise\" : True,\n",
    "\n",
    "# }\n",
    "\n",
    "losses, train_f1, val_f1, last_embeddings = improved_training(\n",
    "    G2_train,\n",
    "    G2_eval,\n",
    "    model_params=model_params,\n",
    "    num_epochs=250,\n",
    "    lr=0.0005,\n",
    "    verbose=True,\n",
    "    return_embeddings = True,\n",
    "    change_topology_params = change_topology_params #change as needed\n",
    ")\n",
    "plot_training_and_validation(losses, val_f1)\n",
    "\n",
    "X,A,y = G1_train\n",
    "print(len(last_embeddings))\n",
    "plot_tsne(last_embeddings, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.3.C Improving Graph Topology for Better Learning\n",
    "\n",
    "• Implement two graph modifications.\n",
    "\n",
    "• Describe your modifications.\n",
    "\n",
    "• What motivated your implementation?\n",
    "\n",
    "• If it helped give a hypothesis on why you think that is? If it did not give a hypothesis why\n",
    "you think it did not help.\n",
    "\n",
    "• Provide relevant plots and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION Q3.3.c\n",
    "# ####################################################\n",
    "# MODIFY THE CODE BELOW \n",
    "# ####################################################  \n",
    "\n",
    "def augment_graph(G):\n",
    "    \"\"\"Augments the graph.\"\"\"\n",
    "    X,A,y = G\n",
    "\n",
    "    return X,A,y\n",
    "    \n",
    "def improved_training(\n",
    "        G_train,\n",
    "        G_eval,\n",
    "        model_params,\n",
    "        num_epochs=200,\n",
    "        lr=0.0005,\n",
    "        verbose=True,\n",
    "        return_embeddings = True,\n",
    "        change_topology_params = {},\n",
    "    ):\n",
    "    \"\"\"\n",
    "    How can you improve the topologies to train better.\n",
    "    \"\"\"\n",
    "\n",
    "    G_train = augment_graph(G_train)\n",
    "    G_train = G_train[0],symmetric_normalize(G_train[1]),G_train[2]\n",
    "\n",
    "    G_eval = augment_graph(G_eval)\n",
    "    G_eval = G_eval[0],symmetric_normalize(G_eval[1]),G_eval[2]\n",
    "\n",
    "    # Initialising the model\n",
    "    model = GraphNeuralNetwork(**model_params)\n",
    "    print(model)\n",
    "\n",
    "    losses, train_f1, val_f1, last_embeddings = train_model(\n",
    "        model,\n",
    "        G_train,\n",
    "        G_eval,\n",
    "        num_epochs=num_epochs,\n",
    "        lr=lr,\n",
    "        verbose=verbose,\n",
    "        return_embeddings = True\n",
    "    )\n",
    "    return losses, train_f1, val_f1, last_embeddings\n",
    "\n",
    "# ####################################################\n",
    "# END OF MODIFICATION\n",
    "# ####################################################  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to run improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "G1_train = read_json_data(G1_TRAIN_DATA_PATH, has_label=True) #returns a list of (X,A,y) - features, Adj Matrix, per Graph label\n",
    "G1_eval = read_json_data(G1_EVAL_DATA_PATH, has_label=True) #returns a list of (X,A,y) - features, Adj Matrix, per Graph label\n",
    "\n",
    "G2_train = read_json_data(G2_TRAIN_DATA_PATH, has_label=True) #returns a list of (X,A,y) - features, Adj Matrix, per Graph label\n",
    "G2_eval = read_json_data(G2_EVAL_DATA_PATH, has_label=True) #returns a list of (X,A,y) - features, Adj Matrix, per Graph label\n",
    "\n",
    "\n",
    "model_params = {    \n",
    "    \"input_dim\":10, \n",
    "    \"hidden_dim\":8,\n",
    "    \"num_layers\":4,\n",
    "}\n",
    "\n",
    "change_topology_params = {\n",
    "    \"augmentation_strategy\":\"eval\",\n",
    "}\n",
    "\n",
    "losses, train_f1, val_f1, last_embeddings = improved_training(\n",
    "    G2_train,\n",
    "    G2_eval,\n",
    "    model_params=model_params,\n",
    "    num_epochs=200,\n",
    "    lr=0.0005,\n",
    "    verbose=True,\n",
    "    return_embeddings = True,\n",
    "    change_topology_params = change_topology_params #change as needed\n",
    ")\n",
    "plot_training_and_validation(losses, val_f1)\n",
    "\n",
    "X,A,y = G1_train\n",
    "print(len(last_embeddings))\n",
    "plot_tsne(last_embeddings, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_dgl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
